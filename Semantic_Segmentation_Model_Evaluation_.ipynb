{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semantic Segmentation - Model Evaluation .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Segmentation\n",
        "\n",
        "We do a qualitative analysis of several pre-trained models (on [Cityscapes](https://www.cityscapes-dataset.com/) dataset) with different backbones, performing *Semantic Segmentation* on different input images.\n",
        "\n",
        "[This notebook](https://github.com/BenoyRNair/SemanticSegmentation) was developed and tested in ***Google Colab***."
      ],
      "metadata": {
        "id": "KSR-JrHsM1WX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Credits\n",
        "\n",
        "MMSegmentation Contributors. (2020).\n",
        "OpenMMLab Semantic Segmentation Toolbox and Benchmark\n",
        "\n",
        "This runs on the [MMSegmentation](https://mmsegmentation.readthedocs.io/en/latest/) modules in [OpenMMLab](https://openmmlab.com/), and builds on:\n",
        "*   [Project](https://github.com/open-mmlab/mmsegmentation)\n",
        "*   [Notebook](https://github.com/open-mmlab/mmsegmentation/blob/master/demo/MMSegmentation_Tutorial.ipynb)\n",
        "*   [Colab Version](https://colab.research.google.com/github/open-mmlab/mmsegmentation/blob/master/demo/MMSegmentation_Tutorial.ipynb)\n"
      ],
      "metadata": {
        "id": "IekFa3m9PNnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Licence\n",
        "@Author [Benoy R Nair](https://github.com/BenoyRNair)\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License.\n",
        "\n",
        "You may obtain a copy of the License at\n",
        "http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied See the License for the specific language governing permissions and limitations under the License.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WCd08gMFCS91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Choose GPU (or TPU) as the 'Hardware Accelerator' for the runtime.\n",
        "\n",
        "We install the required libraries and software in this step; it might take several minutes and might need the 'Runtime' to be restared a couple of times."
      ],
      "metadata": {
        "id": "9cO2etffdUTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ],
      "metadata": {
        "id": "ox9AR7RBM3x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conda\n",
        "\n",
        "*Expect to see something like:*\n",
        "</br> ‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
        "</br> üì¶ Installing...\n",
        "</br> üìå Adjusting configuration...\n",
        "</br> ü©π Patching environment...\n",
        "</br> ‚è≤ Done in 0:00:28\n",
        "</br> üîÅ Restarting kernel...\n"
      ],
      "metadata": {
        "id": "KKhYPLF5fCfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "gsOcMp2FfJzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Expect to see something like:*\n",
        "</br> ‚ú®üç∞‚ú® Everything looks OK!"
      ],
      "metadata": {
        "id": "1AakabPdf1oh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "id": "pkwIVG2bgOYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch\n",
        "\n",
        "We use PyTorch 1.8.0 and CUDA 10.1 for this exercise."
      ],
      "metadata": {
        "id": "qFkzN9N-gXH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install pytorch=1.8.0 torchvision cudatoolkit=10.1 -c pytorch"
      ],
      "metadata": {
        "id": "liknVScugmoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MMCV\n",
        "\n",
        "We install OpenMMLab Computer Vision Foundation Library (mmcv) in this section, and use the version that goes along with PyTorch 1.8.0.\n",
        "\n",
        "Note: *If you are prompted to 'Restart Runtime', do so & try executing this section once again and you should see somethine like 'Requirement already satisfied...' for all the relevant packages.*"
      ],
      "metadata": {
        "id": "IcosFNK-kEv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.8.0/index.html"
      ],
      "metadata": {
        "id": "fHDh4IQnkTUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MMSegmentation\n",
        "\n",
        "MMSegmentation repository from OpenMMLab.\n",
        "\n",
        "Note: *If you are prompted to 'Restart Runtime', do so & try executing this section once again and you should see somethine like 'Requirement already satisfied...' for all the relevant packages.*"
      ],
      "metadata": {
        "id": "mV9LytL6lhLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean any prior instances, if you happen to have any\n",
        "!rm -rf mmsegmentation\n",
        "\n",
        "# Clone repository and install\n",
        "!git clone https://github.com/open-mmlab/mmsegmentation.git \n",
        "%cd mmsegmentation\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "nQ4T8awKlqrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checks\n",
        "\n",
        "Confirming PyTorch and MMSegmentation installtion.\n",
        "\n",
        "*Expect to see something like:*\n",
        "</br> 1.8.0 True\n",
        "</br> 0.23.0\n",
        "\n",
        "If you see an error with mmseg, try executing the 'MMSegmentation' section again."
      ],
      "metadata": {
        "id": "5d7ctFmBnQvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Pytorch installation\n",
        "try:\n",
        "  import torch, torchvision\n",
        "  print(torch.__version__, torch.cuda.is_available())\n",
        "except Exception as e:\n",
        "  print ('Issue with torch; try executing the \\'PyTorch\\' section above again to install PyTorch.')\n",
        "  print (\"\\n:-(\\t\" + str (e))\n",
        "\n",
        "# Check MMSegmentation installation\n",
        "try:\n",
        "  import mmseg\n",
        "  print(mmseg.__version__)\n",
        "except Exception as e:\n",
        "  print ('Issue with mmseg; try executing the \\'MMSegmentation\\' section above again to install MMSegmentation.')\n",
        "  print (\"\\n:-(\\t\" + str (e))"
      ],
      "metadata": {
        "id": "JZNkjhWIngZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model\n",
        "\n",
        "We build the model using pre-trained weights from OpenMMLab for MMSegmentation."
      ],
      "metadata": {
        "id": "7sUdvQtjnlit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Configuration\n",
        "\n",
        "We download a JSON file with links to the pre-trained model weights and the config files required for our MMSegmentation exercise. We parse the file and build the list of models, and retrieve the links to its associated model and config files."
      ],
      "metadata": {
        "id": "LMSkpr-8IHzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/mmsegmentation\n",
        "\n",
        "!pip install wget\n",
        "\n",
        "!wget https://raw.githubusercontent.com/BenoyRNair/SemanticSegmentation/main/MMSegmentation_Model_Config.json\n",
        "\n",
        "import json\n",
        "\n",
        "with open ('MMSegmentation_Model_Config.json') as config_file:\n",
        "    config_data = config_file.read()\n",
        "\n",
        "config_js = json.loads (config_data)\n",
        "models_list = config_js.keys()\n",
        "backbones_list = (config_js[list(config_js.keys())[0]]).keys()"
      ],
      "metadata": {
        "id": "3sUtxZJ_IldP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection\n",
        "\n",
        "We choose the model we want to evaluate in this section; you can choose one from the list available."
      ],
      "metadata": {
        "id": "6eaw8YooXgrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Specify the model.\n",
        "\n",
        "from ipywidgets import interactive\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def model(MODEL):\n",
        "  return MODEL\n",
        "\n",
        "model_widget = interactive (model, MODEL=models_list)\n",
        "display (model_widget)"
      ],
      "metadata": {
        "id": "pDP4IxRdFNdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: The list of backbones depend on the selected model. Execute the section below to update the list of backbones for the chosen model."
      ],
      "metadata": {
        "id": "Fq4X4MH0OHrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Choose the backbone for the specified model.\n",
        "\n",
        "backbones_list = (config_js[model_widget.result].keys())\n",
        "\n",
        "def backbone(BACKBONE):\n",
        "  return BACKBONE\n",
        "\n",
        "backbone_widget = interactive (backbone, BACKBONE=backbones_list)\n",
        "display (backbone_widget)"
      ],
      "metadata": {
        "id": "QvJQKDXaLKcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Segmentor\n",
        "\n",
        "We first identify the model, config & checkpoint files based on the user specified model and backbone.\n",
        "\n",
        "We then download the pretrained weights of the model, and initialize the segmentor with the config file and checkpoint file (links to which were in the JSON file)."
      ],
      "metadata": {
        "id": "hemAc_PmYCYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  selection = (config_js[model_widget.result])[backbone_widget.result]\n",
        "\n",
        "  current_model = model_widget.result\n",
        "  current_backbone = backbone_widget.result\n",
        "\n",
        "  selection_model = selection ['model']\n",
        "  selection_config_file = selection ['config_file']\n",
        "  selection_checkpoint_file = selection ['checkpoint_file']\n",
        "\n",
        "  #print (f'selection_model = {selection_model}')\n",
        "  #print (f'selection_config_file = {selection_config_file}')\n",
        "  #print (f'selection_checkpoint_file = {selection_checkpoint_file}')\n",
        "\n",
        "  %pwd\n",
        "  import wget\n",
        "  import os.path\n",
        "\n",
        "  config_folder = '/content/mmsegmentation/configs/'\n",
        "  checkpoints_folder = '/content/mmsegmentation/checkpoints/'\n",
        "\n",
        "  if not os.path.isdir (checkpoints_folder):\n",
        "    os.mkdir (checkpoints_folder) \n",
        "\n",
        "  if not os.path.exists (checkpoints_folder + selection_checkpoint_file):\n",
        "    wget.download (selection_model, checkpoints_folder)\n",
        "\n",
        "  from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
        "  from mmseg.core.evaluation import get_palette\n",
        "\n",
        "  # build the model from a config file and a checkpoint file\n",
        "  model = init_segmentor (config_folder + selection_config_file, checkpoints_folder + selection_checkpoint_file, device='cuda:0')\n",
        "except Exception as e:\n",
        "  print ('It appears that you have selected a wrong backbone, that isn\\'t available for the chosen model.')\n",
        "  print ('Execute the code section above to refresh the list of backbones.')\n",
        "  print (\"\\n:-(\\t\" + str (e))"
      ],
      "metadata": {
        "id": "NAGnKt-MCKBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model\n",
        "\n",
        "You have an option to choose from one of the images available, or provide one by specifying the link to the image."
      ],
      "metadata": {
        "id": "XtFVvLoEptpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Specify whether you like to provide a custom image or not.\n",
        "\n",
        "def checkbox_interactive (CUSTOM_IMAGE):\n",
        "    return CUSTOM_IMAGE\n",
        "\n",
        "cb_custom_image = interactive (checkbox_interactive, CUSTOM_IMAGE=False)\n",
        "display (cb_custom_image)"
      ],
      "metadata": {
        "id": "oDG29P3cqHzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Specify the input image for the segmentation task.\n",
        "\n",
        "def get_image (IMAGE):\n",
        "  return IMAGE\n",
        "\n",
        "if not cb_custom_image.result:\n",
        "  standard_images_list = [\n",
        "    ('Image 1', './demo/demo.png'),\n",
        "    ('Image 2', 'https://securityamp.com/assets/static/car-dash-view.b137467.dfc408b45abbc5aea697e96dfd512d05.jpg'),\n",
        "    ('Image 3', 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Cars_in_traffic_in_Auckland%2C_New_Zealand_-_copyright-free_photo_released_to_public_domain.jpg/1200px-Cars_in_traffic_in_Auckland%2C_New_Zealand_-_copyright-free_photo_released_to_public_domain.jpg'),\n",
        "    ('Image 4', 'https://i.ibb.co/pxTxmMJ/highway-jam-road-roadway-road-marking-mark.jpg'),\n",
        "    ('Image 5', 'https://upload.wikimedia.org/wikipedia/commons/e/ec/Trailer_on_the_a_busy_road.jpg'),\n",
        "    ('Image 6', 'https://i.ibb.co/kDh7qfF/traffic-road-highway-way-busy-cars.jpg')\n",
        "  ]\n",
        "\n",
        "  image = interactive (get_image, IMAGE=standard_images_list)\n",
        "  display (image)\n",
        "else:\n",
        "  image = interactive (get_image, IMAGE='Link to the image')\n",
        "  display (image)"
      ],
      "metadata": {
        "id": "AEDBJswcsEUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now test the model with the specified image..."
      ],
      "metadata": {
        "id": "aSGJls1ezvtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if ((current_model != model_widget.result) or (current_backbone != backbone_widget.result)):\n",
        "  print ('Model and/ or backbone has been changed.\\nRun the \\'Initialize Segmentor\\' section again.')\n",
        "else:\n",
        "  try:\n",
        "    img = image.result\n",
        "    result = inference_segmentor(model, img)\n",
        "\n",
        "  # show the results\n",
        "    show_result_pyplot(model, img, result, get_palette('cityscapes'), title = 'Model: ' + current_model + '/ Backbone: ' + current_backbone)\n",
        "  except Exception as e:\n",
        "    print ('Unable to process; try another file (or choose from the list of images available, instead of the CUSTOM_IMAGE option).')\n",
        "    print (\"\\n:-(\\t\" + str (e))"
      ],
      "metadata": {
        "id": "Tjt5S_qBcS1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}